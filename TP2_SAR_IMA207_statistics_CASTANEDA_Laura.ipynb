{"cells":[{"cell_type":"markdown","metadata":{"id":"vHxS3VcZ86wa"},"source":["# IMA207 - Practical work on SAR statistics\n","\n","### Emanuele DALSASSO, Florence TUPIN, Cristiano ULONDU MENDES, Thomas BULTINGAIRE\n","\n","### Statistics and despeckling\n","\n","The practical work is divided in 3 parts\n","\n","- A. empirical checking of the distributions seen in course for synthetic speckle\n","- B. computation of equivalent number of looks using images of physically homogeneous areas\n","- C. spatial multi-looking and implementation of the Lee filter\n","\n","You have at your disposal several images of various areas acquired by different acquisition modes.\n","- An oceanfront in São-Paulo acquired by Sentinel-1 sensor (ESA) in GRD (Ground Range Detected) mode\n","- A farmland near from Bologne (Italy) acquired by TerraSAR-X sensor (ESA) in MGD (Multi Look Ground Range Detected) mode\n","- An area near from Rome acquired by TerraSAR-X sensor (ESA) in SLC (Single Look Complex) mode\n","- A temporal stack of images acquired at Flevoland in Netherlands by Alos sensor (JAXA) in SLC mode\n","\n","Some useful functions are available in the file *mvalab.py*.\n","\n","### Name: **WRITE YOUR NAME HERE**\n","\n","#### Instructions\n","\n","To solve this practical session, answer the questions below. Then export the notebook with the answers using the menu option **File -> Download as -> Notebook (.ipynb)**. Then [submit the resulting file on e-campus by next week."]},{"cell_type":"markdown","metadata":{"id":"c4NgoZfsEcW6"},"source":["### Import the libraries and packages we are going to use\n","The following cell imports all that is going to be necessary for the practical work"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3Lp7xfMElLD"},"outputs":[],"source":["!wget https://perso.telecom-paristech.fr/tupin/TPSAR/mvalab.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VU9jOLPZAlZ7"},"outputs":[],"source":["import scipy\n","from scipy import signal\n","import scipy.signal\n","import scipy as spy\n","import scipy.fftpack\n","from scipy import ndimage\n","from scipy import special\n","from scipy import ndimage\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import mvalab as mvalab\n","from urllib.request import urlopen\n","import cmath\n","\n","plt.rcParams['figure.figsize'] = [15, 15]\n","plt.rcParams['figure.max_open_warning'] = 30"]},{"cell_type":"markdown","source":["## A. Single look data distributions\n","\n","In this part, we will simulate an SLC (Single Look Complex) SAR image representing an homogeneous area and analyze the pdfs of its intensity and phase."],"metadata":{"id":"9VZqPF1gKHyE"}},{"cell_type":"markdown","source":["#### Single look data simulation\n","\n","According to the Goodman model, the real and imaginary parts of each pixel of an SLC SAR image are independent and identically distributed according to a Gaussian distribution centered and of variance equal to the reflectivity of the pixel divided by 2.\\\n","Choose randomly a reflectity value $R$ in the interval $[100, 200]$ and create a SLC SAR image of size $150\\times 150$ representing an homogeneous area of reflectivity $R$."],"metadata":{"id":"iEPSQNVDKHnN"}},{"cell_type":"code","source":["# Chose the reflectivity of the homogeneous area\n","R = ... #complete\n","\n","# Simulate the corresponding SLC image\n","ima_slc = ... #complete\n","mvalab.visusar(np.abs(ima_slc))"],"metadata":{"id":"U2JFYggjKLf0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Data distributions for an homogeneous area\n","\n","compute the distribution of the phase and intensity of your image.\n","Then, estimate the coefficient of variation:  \n","$\\gamma=\\frac{\\sigma}{\\mu}$ using intensity data (square of the modulus of the complex field)"],"metadata":{"id":"dfEkpe_XKaqe"}},{"cell_type":"code","source":["# Compute the intensity and the phase\n","ima_int = ... #complete\n","ima_ph = ... #complete"],"metadata":{"id":"OLk6lbcPKcP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the histograms and verify they match the theoretical distribution\n","# Use the right range of values to plot the histogram\n","# Choose the right distribution to do the fitting\n","\n","# fitting of the distributions\n","# use the following ones :\n","# Gaussian pdf : scipy.stats.uniform\n","# Rayleigh pdf : scipy.stats.rayleigh\n","# Exponential pdf : scipy.stats.expon\n","\n","#example for real part of the data\n","plt.figure()\n","_, bins, _ = plt.hist(np.real(ima_slc).ravel(),bins='auto',density=True,range=[-100,100])  # Gaussian distribution\n","mu, sigma = scipy.stats.norm.fit(np.real(ima_slc))\n","best_fit_line = scipy.stats.norm.pdf(bins, mu, sigma)\n","plt.plot(bins, best_fit_line)\n","plt.title('histogram of real part')\n","plt.show()\n","\n","\n","#complete for phase data: Uniform distribution\n","plt.figure()\n","... #complete\n","plt.plot(bins, best_fit_line)\n","plt.title('histogram of phase')\n","plt.show()\n","\n","\n","#complete for intensity data: Exponential (Gamma) distribution\n","plt.figure()\n","... #complete\n","plt.plot(bins, best_fit_line)\n","plt.title('histogram of intensity')\n","plt.show()"],"metadata":{"id":"PRQuZyxEKfjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute the coefficient of variation on the homogeneous area in intensity\n","\n","m_I = ... #complete\n","sigma_I = ... #complete\n","coeff_var_I = sigma_I/m_I\n","print(coeff_var_I)"],"metadata":{"id":"1N_-Hw7YKjIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question A.1.\n","\n","Did you find the distributions seen in the course ? (recapitulate them).\n","Did you find the correct value for the coefficient of variation ? Could this coefficient be less than the theoretical value ?"],"metadata":{"id":"7vcdz42EKlvU"}},{"cell_type":"markdown","source":["### Answer A.1.\n"],"metadata":{"id":"6W0JtschKoT9"}},{"cell_type":"markdown","source":["## B. Computation of the Equivalent Number of looks on homogeneous areas\n","In this part you have at your disposal 2 images of a part a ocean (São-Paulo) and a part of a field (Bologne, Italy). The first is acquired by Sentinel-1 GRD, and the second by TerraSAR-X GRD. The multi-looking has been done by the data provider (ESA, European Space Agency).\n","\n","Use the value of the coefficient of variation to find the Equivalent Number of Looks (ENL) of the Sentinel-1 GRD and TerraSAR-X GRD data.\n","The formula is :\n","- $\\gamma_I=\\frac{1}{\\sqrt{L}}$ for intensity data"],"metadata":{"id":"H_2dRxVpKy78"}},{"cell_type":"code","source":["# Download the images\n","!wget \"https://partage.imt.fr/index.php/s/M3yeW5ozcsHyigR/download/s1_grd_saopaulo.npy\"\n","!wget \"https://partage.imt.fr/index.php/s/TTRfS6XKCzSM6cS/download/tsx_grd_bologne.npy\""],"metadata":{"id":"mmHvclrLK1rU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im_s1grd = np.load(\"s1_grd_saopaulo.npy\").astype(np.float32) #amplitude\n","im_s1grd_mer = im_s1grd[50:300, 100:350]\n","mvalab.visusar(...)\n","\n","# compute coefficient of variation and number of looks\n","coeff_var_grd = ... #complete\n","L_grd = ... #complete\n","print('--- coeff var and L ---')\n","print(coeff_var_grd)\n","print(L_grd)"],"metadata":{"id":"dB5Bqn11fH19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["im_tsxgrd = np.load(\"tsx_grd_bologne.npy\").astype(np.float32) #amplitude\n","im_tsxgrd_champ = im_tsxgrd[700:950, 300:550]\n","mvalab.visusar(...)\n","\n","# compute coefficient of variation and number of looks\n"],"metadata":{"id":"XDvHHN9ifkXv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question B.1\n","Comment the number of looks you have found for GRD date from Sentinel-1 and TerraSAR-X (is it an integer value ? why not ? what does it mean ?)."],"metadata":{"id":"Rsbp5lTngKtU"}},{"cell_type":"markdown","source":["### Answer B.1"],"metadata":{"id":"1PB6LT-DgU5C"}},{"cell_type":"markdown","source":["## C. Spatial multi-looking and implementation of the Lee filter\n","\n","In this part we will try simple speckle reduction method using the following step :\n","- first we will compute a mean filter\n","- then we will compute the local coefficient of variation (using the same size for the moving window)\n","- finally we will combine these two results to obtain the Lee filter."],"metadata":{"id":"i6O2Qqf_ga0B"}},{"cell_type":"markdown","source":["## C.1 Computation of the mean filter\n","Compute the mean filter using a 2D convolution."],"metadata":{"id":"UETZdeQvgfOH"}},{"cell_type":"code","source":["# Download the image\n","!wget \"https://partage.imt.fr/index.php/s/cbRqjnSJEfD2zJ8/download/tsx_slc_rome.npy\""],"metadata":{"id":"y7f-sevOgZSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ima_tsxslc = np.load(\"tsx_slc_rome.npy\") #amplitude\n","\n","# take the intensity\n","ima_int = ... #complete\n","mvalab.visusar(...)\n","\n","# create the average window\n","size_window = ...\n","mask_loc = ... #complete\n","\n","# compute the mean image (intensity data)\n","ima_int_mean = ... #complete\n","\n","# display the result\n","..."],"metadata":{"id":"sTF2l-kLgibu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question C.1\n","What is the effect of the mean filter ? (advantages and drawbacks). What is the influence of the window size ?"],"metadata":{"id":"Pm5fObhWgr6o"}},{"cell_type":"markdown","source":["### Answer C.1"],"metadata":{"id":"11fbF69kgvv2"}},{"cell_type":"markdown","source":["## C.2 Lee filter\n","\n","Given a neighborhood, the Lee filter of an image $I_s$ can be computed by the following steps:\n","\n","*   Compute the local mean of the image $\\hat{\\mu}_{s}$\n","*   Compute $k_s$ given by:\n","$$\n","  k_s=1- \\frac{\\gamma_{Sp}^2}{\\hat{\\gamma}_s^2}\n","$$\n","where $\\gamma_{Sp}$ is the theoretical value of the coefficient of variation for a pure speckle ($\\gamma_{Sp}=\\frac{1}{\\sqrt{L}}$ for a L-look intensity image), and $\\hat{\\gamma}_s$ is the empirical value of the coefficient of variation for the given neighborhood.\n","*   Compute the final filtered image\n","$$\n","  \\hat{I}_s= \\hat{\\mu}_{s}+k_s (I_s-\\hat{\\mu}_{s})\n","$$\n","\n","Create a function performing Lee filter on an image, for a given neighborhood and number $L$ of look.\n","\n","Then, knowing that a SLC image is a 1-look image, compute the Lee filter on the intensity image of \"ima_tsxslc\""],"metadata":{"id":"umQp1nNhgx9p"}},{"cell_type":"code","source":["def lee_filter(im, neighborhood=7, L=1, visualize=False):\n","\n","  # Mask\n","  mask = ... #complete\n","\n","  # Compute local mean image\n","  im_mean = ... #complete\n","\n","  # Compute local coefficient of variation (thanks to local variance and local mean)\n","  im_var = ... #complete\n","  ks = ... #complete\n","  ks = np.clip(ks, 0, 1)\n","\n","  # Compute Lee filter\n","  filtered_im = ... #complete\n","\n","  # Visualizations\n","  if visualize:\n","    mvalab.visusar(np.sqrt(im_mean))\n","    mvalab.visusar(im_var)\n","    mvalab.visusar(np.sqrt(ks))\n","\n","  return filtered_im\n","\n","\n","lee_filtered_int = lee_filter(..., neighborhood=..., L=..., visualize=True) #complete\n","mvalab.visusar(...)"],"metadata":{"id":"qBhFvqh4hFXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question C.2\n","Which information is enhanced in the image of the local standard deviation ? In the image of the local coefficient of variation ? Which one is the more useful ?"],"metadata":{"id":"_3kJJZH7hJTZ"}},{"cell_type":"markdown","source":["### Answer C.2"],"metadata":{"id":"PiPCgOZ7hM89"}},{"cell_type":"markdown","source":["### Question C.3\n","\n","Compare the results of the mean filter and the Lee filter. Study the influence of the size of the window of the filters.\n"],"metadata":{"id":"l495kEUhiADa"}},{"cell_type":"markdown","source":["### Answer C.3"],"metadata":{"id":"KPXEeE5viDtv"}},{"cell_type":"markdown","source":["## Filtering of image \"Lely\" and comparison with a deep learning algorithm\n","In this part, we will repeat the process done above to denoise a crop of image \"Lely\" using the Lee filter. Then, we will compare it with the result of a deep learning algorithm called SAR2SAR (https://arxiv.org/abs/2006.15037)."],"metadata":{"id":"gAFGtvJ7iVbO"}},{"cell_type":"markdown","source":["## C.4 Denoised image: SAR2SAR\n","The Lee filter presents some limits. More recent approaches to suppress noise rely on sofisticated algorithms. You can plot the image of Lely denoised using a deep learning algorthm called SAR2SAR and compare visually the result with the image filtered using the Lee filter.\n","  "],"metadata":{"id":"s-9qhufTiXK5"}},{"cell_type":"code","source":["# Download the image\n","!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/multitemp/lely_tuple_multitemp.IMA\n","!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/multitemp/lely_tuple_multitemp.dim"],"metadata":{"id":"TwHaU-5fiorc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["part_lely_slc = mvalab.imz2mat('lely_tuple_multitemp.IMA')[0] #date is on thrid axis of part_lely_slc\n","part_lely_slc = part_lely_slc[:,:,0] #single look complex image\n","mvalab.visusar(...)\n","\n","# using your previous code, filter the image part_lely_int with the Lee filter\n","..."],"metadata":{"id":"zS4R8XfFigq_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this image has already been processed by a CNN based filter\n","!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/denoised_SAR2SAR/lely_tuple_multitemp_SAR2SAR.IMA\n","!wget https://perso.telecom-paristech.fr/tupin/TPSAR/pilelely/denoised_SAR2SAR/lely_tuple_multitemp_SAR2SAR.dim\n","im_lely_multitemp_denoised = mvalab.imz2mat('lely_tuple_multitemp_SAR2SAR.IMA')\n","im1_d = np.abs(im_lely_multitemp_denoised[0][:,:,0]) #amplitude\n","mvalab.visusar(...)"],"metadata":{"id":"_rvT_56mi_Ig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Question C.4\n","Do a comparison between the CNN filtering and the Lee filter. Comment the two results. Are homogeneous areas well restored? Do the methods preserve edges and fine structures? Are artifacts introduced?"],"metadata":{"id":"5MwX98FxjENM"}},{"cell_type":"markdown","source":["### Answer C.4"],"metadata":{"id":"YIQe_gnijFyb"}},{"cell_type":"markdown","source":["## C.5 Method noise\n","Performances of a denoising algorithm can be visually interpreted by looking at the *residual noise* (i.e. the ratio between the noisy image and the denoised image, in intensity). For a quantitative evaluation, we can look at the noise statistics, knowing that, in intensity, statistics of speckle S are:\n","- $\\mu_S=1$\n","- $\\sigma^2_S = \\frac{1}{L}$"],"metadata":{"id":"zQkfprwhjV7u"}},{"cell_type":"markdown","source":["### Question C.5\n","Compute the aforementioned ratio image, mean value and variance for the image restored using the Lee filter and the result of SAR2SAR. Comment the results.\n","\n","What is the interest of computing the method noise ? What are your conclusions for the two previous filters ?"],"metadata":{"id":"9dGMFMjsjZ6U"}},{"cell_type":"markdown","source":["### Answer C.5"],"metadata":{"id":"twerr6rkjcs1"}},{"cell_type":"code","source":["# Plot the residual noise\n","res_noise_lee = ... #complete\n","mvalab.visusar(res_noise_lee)\n","mean_lee = np.mean(res_noise_lee)\n","var_lee = np.var(res_noise_lee)\n","\n","res_noise_deep = ... #complete\n","mvalab.visusar(res_noise_deep)\n","mean_deep = np.mean(res_noise_deep)\n","var_deep = np.var(res_noise_deep)\n","\n","print('LEE FILTER: mean = '+str(mean_lee)+' and var = '+str(var_lee))\n","print('SAR2SAR: mean = '+str(mean_deep)+' and var = '+str(var_deep))"],"metadata":{"id":"zbLqOF9mjipm"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}